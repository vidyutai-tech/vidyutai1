{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Consumption Anomaly Detection\n",
    "\n",
    "This notebook demonstrates anomaly detection techniques for energy consumption data using machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "\n",
    "Load energy consumption data from various sources and explore its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample code to load data\n",
    "# In a real scenario, this would connect to your database or data files\n",
    "\n",
    "# Generate sample data for demonstration\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2023-01-01', periods=1000, freq='H')\n",
    "base_consumption = 100 + 20 * np.sin(np.arange(1000) * (2 * np.pi / 24))  # Daily cycle\n",
    "weekly_pattern = 15 * np.sin(np.arange(1000) * (2 * np.pi / (24 * 7)))    # Weekly cycle\n",
    "noise = np.random.normal(0, 5, 1000)                                      # Random noise\n",
    "\n",
    "# Add some anomalies\n",
    "anomalies = np.zeros(1000)\n",
    "anomaly_indices = np.random.choice(range(1000), size=20, replace=False)\n",
    "anomalies[anomaly_indices] = np.random.normal(0, 50, 20)\n",
    "\n",
    "# Combine components\n",
    "consumption = base_consumption + weekly_pattern + noise + anomalies\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'timestamp': dates,\n",
    "    'energy_consumption': consumption\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the data\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df['timestamp'], df['energy_consumption'])\n",
    "plt.title('Energy Consumption Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Energy Consumption (kWh)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Extract relevant features from the time series data for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract time-based features\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "# Calculate rolling statistics\n",
    "df['rolling_mean_24h'] = df['energy_consumption'].rolling(window=24).mean()\n",
    "df['rolling_std_24h'] = df['energy_consumption'].rolling(window=24).std()\n",
    "\n",
    "# Calculate the difference from expected patterns\n",
    "df['consumption_diff'] = df['energy_consumption'] - df['rolling_mean_24h']\n",
    "\n",
    "# Drop NaN values from rolling calculations\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Display the engineered features\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anomaly Detection Model\n",
    "\n",
    "Implement and train an anomaly detection model using Isolation Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare features for anomaly detection\n",
    "features = ['energy_consumption', 'hour', 'day_of_week', 'rolling_mean_24h', 'rolling_std_24h', 'consumption_diff']\n",
    "X = df_clean[features].copy()\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train Isolation Forest model\n",
    "model = IsolationForest(n_estimators=100, contamination=0.02, random_state=42)\n",
    "model.fit(X_scaled)\n",
    "\n",
    "# Predict anomalies\n",
    "df_clean['anomaly_score'] = model.decision_function(X_scaled)\n",
    "df_clean['is_anomaly'] = model.predict(X_scaled) == -1  # -1 for anomalies, 1 for normal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the detected anomalies\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_clean['timestamp'], df_clean['energy_consumption'], label='Energy Consumption')\n",
    "plt.scatter(df_clean[df_clean['is_anomaly']]['timestamp'], \n",
    "            df_clean[df_clean['is_anomaly']]['energy_consumption'], \n",
    "            color='red', label='Anomalies')\n",
    "plt.title('Energy Consumption with Detected Anomalies')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Energy Consumption (kWh)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Evaluate the performance of the anomaly detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Count detected anomalies\n",
    "anomaly_count = df_clean['is_anomaly'].sum()\n",
    "print(f\"Number of detected anomalies: {anomaly_count}\")\n",
    "print(f\"Percentage of data points flagged as anomalies: {anomaly_count / len(df_clean) * 100:.2f}%\")\n",
    "\n",
    "# Analyze anomaly characteristics\n",
    "anomalies_df = df_clean[df_clean['is_anomaly']]\n",
    "print(\"\\nStatistics of normal vs. anomalous points:\")\n",
    "print(df_clean.groupby('is_anomaly')['energy_consumption'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-time Anomaly Detection Function\n",
    "\n",
    "Create a function that can be used for real-time anomaly detection in the production system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def detect_anomalies(new_data, model, scaler, feature_columns):\n",
    "    \"\"\"\n",
    "    Detect anomalies in new energy consumption data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    new_data : pandas.DataFrame\n",
    "        New data points to check for anomalies\n",
    "    model : trained anomaly detection model\n",
    "        Pre-trained anomaly detection model\n",
    "    scaler : sklearn.preprocessing.StandardScaler\n",
    "        Fitted scaler for feature standardization\n",
    "    feature_columns : list\n",
    "        List of feature column names to use\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Original data with anomaly scores and flags added\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    X = new_data[feature_columns].copy()\n",
    "    \n",
    "    # Standardize features\n",
    "    X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Predict anomalies\n",
    "    new_data['anomaly_score'] = model.decision_function(X_scaled)\n",
    "    new_data['is_anomaly'] = model.predict(X_scaled) == -1\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "# Example of using the function with new data\n",
    "# In a real system, this would be called with new incoming data\n",
    "# new_predictions = detect_anomalies(new_data, model, scaler, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model for Production\n",
    "\n",
    "Save the trained model and scaler for use in the production system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model and scaler\n",
    "joblib.dump(model, '../models/isolation_forest_model.pkl')\n",
    "joblib.dump(scaler, '../models/feature_scaler.pkl')\n",
    "joblib.dump(features, '../models/feature_list.pkl')\n",
    "\n",
    "print(\"Model and preprocessing objects saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "This notebook demonstrated a basic approach to anomaly detection in energy consumption data. For production use, consider:\n",
    "\n",
    "1. Collecting and using real historical data\n",
    "2. Implementing more sophisticated models (LSTM, Prophet, etc.)\n",
    "3. Adding domain-specific features\n",
    "4. Setting up automated retraining\n",
    "5. Implementing real-time alerting based on detected anomalies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}